{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5bb0ad",
   "metadata": {},
   "source": [
    "Purpose: Figure out how to balance all stressors without errors when drought is the random forest test set.<br>\n",
    "Author: Anna Pardo<br>\n",
    "Date initiated: July 20, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53dc1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed4feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_data(path_to_tpm,single_stress=\"none\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path_to_tpm = full path to file containing raw TPM, columns for Sample, BioProject, & Treatment\n",
    "        single_stress = a single stressor to which the data must be subsetted, or \"none\" (default)\n",
    "    \"\"\"\n",
    "    # load the TPM data\n",
    "    raw_tpm = pd.read_csv(path_to_tpm,sep=\"\\t\",header=\"infer\")\n",
    "    # return the dataframe\n",
    "    return raw_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14015320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold_selector(data):\n",
    "    selector = VarianceThreshold()\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2786b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_strategy(X,y,n_samples, t='majority'):\n",
    "    target_classes = ''\n",
    "    if t == 'majority':\n",
    "        target_classes = y.value_counts() > n_samples\n",
    "    elif t == 'minority':\n",
    "        target_classes = y.value_counts() < n_samples\n",
    "    tc = target_classes[target_classes == True].index\n",
    "    sampling_strategy = {}\n",
    "    for target in tc:\n",
    "        sampling_strategy[target] = n_samples\n",
    "    return sampling_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d647c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_sample(X,y):\n",
    "    count = y.value_counts()\n",
    "    n_samples = count.median().astype(np.int64)\n",
    "\n",
    "    # downsample majority classes\n",
    "    under_sampler = ClusterCentroids(sampling_strategy=sampling_strategy(X,y,n_samples,t='majority'))\n",
    "    X_under, y_under = under_sampler.fit_resample(X, y)\n",
    "\n",
    "    # upsample minority classes\n",
    "    over_sampler = SMOTE(sampling_strategy=sampling_strategy(X_under, y_under,n_samples, t='minority'),k_neighbors=2)\n",
    "    X_bal, y_bal = over_sampler.fit_resample(X_under, y_under)\n",
    "\n",
    "    return X_bal,y_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "369b117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(train,sampling):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        train = TPM dataframe with columns for Sample, Treatment, BioProject, and Label (training set only!)\n",
    "        sampling = \"up\" or \"median\" (note, should be lowercase)\n",
    "    \"\"\"\n",
    "    # drop control samples\n",
    "    traintreat = train[train[\"Treatment\"]!=\"Control\"]\n",
    "    # pull out control samples and save for later\n",
    "    cont = train[train[\"Treatment\"]==\"Control\"]\n",
    "\n",
    "    # generate list of stressors in dataframe\n",
    "    stressors = list(traintreat[\"Treatment\"].unique())\n",
    "\n",
    "    # set up 5-way class labeling\n",
    "    cl = []\n",
    "    for i in range(len(stressors)):\n",
    "        cl.append(i)\n",
    "    cldf = pd.DataFrame(list(zip(stressors,cl)),columns=[\"Treatment\",\"Class\"])\n",
    "\n",
    "    # merge with traintreat\n",
    "    ttclass = cldf.merge(traintreat,how=\"right\")\n",
    "\n",
    "    # drop BioProject & Treatment\n",
    "    ttclass = ttclass.drop([\"BioProject\",\"Treatment\"],axis=1)\n",
    "    # set Sample as index\n",
    "    ttclass = ttclass.set_index(\"Sample\")\n",
    "    # split into X and y\n",
    "    X = ttclass.drop(\"Class\",axis=1)\n",
    "    y = ttclass[\"Class\"]\n",
    "\n",
    "    if sampling==\"up\":\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_res, y_res = sm.fit_resample(X,y)\n",
    "    elif sampling==\"median\":\n",
    "        X_res, y_res = median_sample(X,y)\n",
    "\n",
    "    # stick X and y back together\n",
    "    upsamp = pd.concat([y_res,X_res],axis=1)\n",
    "    # set a Label column\n",
    "    upsamp[\"Label\"] = 1\n",
    "    # drop the Class column\n",
    "    upsamp = upsamp.drop(\"Class\",axis=1)\n",
    "\n",
    "    # drop Sample, BioProject, and Treatment from control data\n",
    "    cont = cont.drop([\"Sample\",\"BioProject\",\"Treatment\"],axis=1)\n",
    "    # set Label column for controls\n",
    "    cont[\"Label\"] = 0\n",
    "\n",
    "    # append cont to upsamp\n",
    "    alldf = pd.concat([upsamp,cont],axis=0)\n",
    "\n",
    "    # split into X and y again\n",
    "    X_all = alldf.drop(\"Label\",axis=1)\n",
    "    y_all = alldf[\"Label\"]\n",
    "    # upsample the controls to match the stressed samples\n",
    "    sm2 = SMOTE(random_state=42)\n",
    "    X_all_res,y_all_res = sm2.fit_resample(X_all,y_all)\n",
    "\n",
    "    return X_all_res,y_all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c774bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_split_transform(raw_tpm):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        raw_tpm = dataframe containing raw TPM values, columns for Sample, BioProject, Treatment\n",
    "    \"\"\"\n",
    "    # temporarily, drop BioProject & Treatment columns\n",
    "    blt = raw_tpm[[\"Sample\",\"BioProject\",\"Treatment\"]]\n",
    "    tpmi = raw_tpm.set_index(\"Sample\").drop([\"BioProject\",\"Treatment\"],axis=1)\n",
    "    # remove zero-variance genes\n",
    "    vttpm = variance_threshold_selector(tpmi)\n",
    "    # log-transform TPM\n",
    "    vttpm_log = vttpm.apply(lambda x: np.log2(x+1))\n",
    "    # add treatment, labels, and BioProject back in\n",
    "    labeled = blt.merge(vttpm_log.reset_index().rename(columns={\"index\":\"Sample\"}))\n",
    "    # drop rows containing NaN values\n",
    "    labeled = labeled.dropna(axis=0)\n",
    "    # return dataframe\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fedea231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_prep_stressor(stressor,dataframe,sampling):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        stressor = stressor to hold out for testing (all BioProjects)\n",
    "        dataframe = log TPM dataframe with Sample, BioProject, Treatment columns (or Sample as index)\n",
    "        sampling = str: \"median\",\"up\" (should be lowercase; to be fed into resample())\n",
    "    \"\"\"\n",
    "    # replace DroughtRepeat with Drought in TPM matrix (if exists)\n",
    "    if \"DroughtRepeat\" in dataframe[\"Treatment\"].unique():\n",
    "        dataframe[\"Treatment\"].mask(dataframe[\"Treatment\"]==\"DroughtRepeat\",\"Drought\",inplace=True)\n",
    "    # generate list of unique BioProjects containing the test stressor\n",
    "    sbp = dataframe[dataframe[\"Treatment\"]==stressor][\"BioProject\"].unique()\n",
    "    # split test from train data\n",
    "    test = dataframe[dataframe[\"BioProject\"].isin(sbp)]\n",
    "    test = test[test[\"Treatment\"].isin([stressor,\"Control\"])]\n",
    "    # add Label column to test data\n",
    "    label = []\n",
    "    for i in test[\"Treatment\"].unique():\n",
    "        if i==\"Control\":\n",
    "            label.append(0)\n",
    "        else:\n",
    "            label.append(1)\n",
    "    labdf = pd.DataFrame(list(zip(test[\"Treatment\"].unique(),label)),columns=[\"Treatment\",\"Label\"])\n",
    "    test = test.merge(labdf,how=\"right\")\n",
    "    # pull out training data\n",
    "    train = dataframe[~dataframe[\"Sample\"].isin(test[\"Sample\"])]\n",
    "    # resample training data\n",
    "    train_X, y_train = resample(train,sampling)\n",
    "    # for test set, make Sample the index again\n",
    "    test = test.set_index(\"Sample\")\n",
    "    # drop BioProject and Treatment columns from test set\n",
    "    test = test.drop([\"BioProject\",\"Treatment\"],axis=1)\n",
    "    # generate X_train, X_test, y_train, and y_test\n",
    "    ## where X = gene expression values and y = class labels\n",
    "    test_X = test.drop(\"Label\",axis=1)\n",
    "    y_test = test[\"Label\"]\n",
    "    # for X_train and X_test: scale data to a z-score\n",
    "    scalar = StandardScaler()\n",
    "    X_train = scalar.fit_transform(train_X)\n",
    "    X_test = scalar.fit_transform(test_X)\n",
    "    # return training and test data\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa001bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tpm = load_clean_data(\"../../data/rawtpm_bptreat_noPEG.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9644ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_tpm = pre_split_transform(cleaned_tpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d26668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stressor = \"Drought\"\n",
    "single_stress = \"Drought\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7e41791",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = \"median\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f75a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = log_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e55faa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leviathan22/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/leviathan22/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_18925/765861191.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  upsamp[\"Label\"] = 1\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_prep_stressor(single_stress,log_tpm,sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ce57980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break down the function into little pieces to find out where it went wrong\n",
    "\n",
    "# generate list of unique BioProjects containing the test stressor\n",
    "sbp = dataframe[dataframe[\"Treatment\"]==stressor][\"BioProject\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eccff53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test from train data\n",
    "test = dataframe[dataframe[\"BioProject\"].isin(sbp)]\n",
    "test = test[test[\"Treatment\"].isin([stressor,\"Control\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "874af78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Label column to test data\n",
    "label = []\n",
    "for i in test[\"Treatment\"].unique():\n",
    "    if i==\"Control\":\n",
    "        label.append(0)\n",
    "    else:\n",
    "        label.append(1)\n",
    "labdf = pd.DataFrame(list(zip(test[\"Treatment\"].unique(),label)),columns=[\"Treatment\",\"Label\"])\n",
    "test = test.merge(labdf,how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56ef559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out training data\n",
    "train = dataframe[~dataframe[\"Sample\"].isin(test[\"Sample\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4741424",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from here we are breaking down chunks of the resample() function\n",
    "\n",
    "# drop control samples\n",
    "traintreat = train[train[\"Treatment\"]!=\"Control\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84130c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out control samples and save for later\n",
    "cont = train[train[\"Treatment\"]==\"Control\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c927a8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heat', 'Cold', 'Salt', 'DroughtRepeat', 'Low_Nitrogen', 'Flooding']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate list of stressors in dataframe\n",
    "stressors = list(traintreat[\"Treatment\"].unique())\n",
    "stressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280c62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
